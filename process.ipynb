{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install textblob \n",
    "# !pip install pyspark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.mllib.clustering import StreamingKMeans\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from textblob import TextBlob\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import json\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = \"localhost\"\n",
    "STREAM_PORT = 9999\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "23/05/02 20:01:25 WARN Utils: Your hostname, DESKTOP-CBR75GN resolves to a loopback address: 127.0.1.1; using 172.21.102.147 instead (on interface eth0)\n",
      "23/05/02 20:01:25 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/05/02 20:01:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext.getOrCreate()\n",
    "sc.setCheckpointDir(\"spark_checkpoint\")\n",
    "ssc = StreamingContext(sc, 10)\n",
    "submissions = ssc.socketTextStream(HOST, STREAM_PORT)\n",
    "sc.setLogLevel(\"ERROR\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_submission(message):\n",
    "\n",
    "    submission = json.loads(message)\n",
    "\n",
    "    title = submission['message']\n",
    "    metadata = submission['metadata']\n",
    "    author = metadata['author_name']\n",
    "    date = metadata['date']\n",
    "    score = metadata['score']\n",
    "    num_comments = metadata['num_comments']\n",
    "    upvote_ratio = metadata['upvote_ratio']\n",
    "    text = metadata['text']\n",
    "    subreddit_name = metadata['subreddit_name']\n",
    "\n",
    "    title_polarity, title_subjectivity = TextBlob(title).sentiment\n",
    "    text_polarity, text_subjectivity = TextBlob(text).sentiment\n",
    "\n",
    "    return {\n",
    "        'title': title,\n",
    "        'text': text,\n",
    "        'author': author,\n",
    "        'date': date,\n",
    "        'score': score,\n",
    "        'num_comments': num_comments,\n",
    "        'upvote_ratio': upvote_ratio,\n",
    "        'text': text,\n",
    "        'subreddit_name': subreddit_name,\n",
    "        'subreddit_hash': hash(subreddit_name),\n",
    "        'title_polarity': title_polarity,\n",
    "        'title_subjectivity': title_subjectivity,\n",
    "        'text_polarity': text_polarity,\n",
    "        'text_subjectivity': text_subjectivity\n",
    "    }\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add processing to the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = submissions.map(process_submission)\n",
    "# submissions.pprint()\n",
    "training_data = submissions.map(lambda x: Vectors.dense(\n",
    "    [x['title_polarity'], x['title_subjectivity'], x['text_polarity'], x['text_subjectivity'], x[\"subreddit_hash\"]]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "model = StreamingKMeans(k, decayFactor=1.0).setRandomCenters(5, 1.0, 0)\n",
    "model.trainOn(training_data)\n",
    "result = model.predictOn(training_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing sentiment by cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create viz.json if doesn't exist and set every cluster size to 0\n",
    "with open(\"sentiment.json\", \"w\") as f:\n",
    "    total_data = {}\n",
    "    for i in range(k):\n",
    "        total_data[str(i)] = (0,0,0,0,0)\n",
    "    json.dump(total_data,f)\n",
    "\n",
    "def update_cluster_sentiment(rdd):\n",
    "    if not rdd.isEmpty():\n",
    "        for x in rdd.collect(): \n",
    "            with open(\"sentiment.json\", \"r\") as f:\n",
    "                total_data = json.load(f)\n",
    "            total_data[str(x[0])] = tuple(sum(t) for t in zip(total_data[str(x[0])], x[1]))\n",
    "            with open(\"sentiment.json\", \"w\") as f:\n",
    "                json.dump(total_data,f)\n",
    "\n",
    "# Calculate the average sentiment scores for each cluster\n",
    "cluster_sentiment = submissions.map(lambda x: ((x['title_polarity'], x['title_subjectivity'], x['text_polarity'], x['text_subjectivity'],1),Vectors.dense([x['title_polarity'], x['title_subjectivity'], x['text_polarity'], x['text_subjectivity'], x['subreddit_hash']])))\n",
    "cluster_sentiment = model.predictOnValues(cluster_sentiment)\n",
    "cluster_sentiment = cluster_sentiment.map(lambda x: (x[1],x[0]))\n",
    "cluster_sentiment = cluster_sentiment.reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1], x[2] + y[2], x[3] + y[3], x[4] + y[4]))\n",
    "cluster_sentiment.foreachRDD(lambda rdd: update_cluster_sentiment(rdd))\n",
    "# cluster_sentiment = cluster_sentiment.mapValues(lambda x: (x[0] / x[4], x[1] / x[4], x[2] / x[4], x[3] / x[4]))\n",
    "# cluster_sentiment.pprint()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing location by cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create viz.json if doesn't exist and set every cluster size to 0\n",
    "with open(\"subreddit.json\", \"w\") as f:\n",
    "    total_data = {}\n",
    "    for i in range(k):\n",
    "        total_data[str(i)] = [\"empty\"]\n",
    "    json.dump(total_data,f)\n",
    "\n",
    "def update_cluster_subreddit_names(rdd):\n",
    "    if not rdd.isEmpty():\n",
    "        for x in rdd.collect(): \n",
    "            with open(\"subreddit.json\", \"r\") as f:\n",
    "                total_data = json.load(f)\n",
    "            total_data[str(x[0])] = total_data[str(x[0])] + list(x[1])\n",
    "            with open(\"subreddit.json\", \"w\") as f:\n",
    "                json.dump(total_data,f)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Calculate the most common locations for each cluster\n",
    "cluster_locations = submissions.map(lambda x: (x['subreddit_name'],Vectors.dense([x['title_polarity'], x['title_subjectivity'], x['text_polarity'], x['text_subjectivity'], x['subreddit_hash']])))\n",
    "cluster_locations = model.predictOnValues(cluster_locations)\n",
    "cluster_locations = cluster_locations.map(lambda x: (x[1],x[0]))\n",
    "cluster_locations = cluster_locations.groupByKey()\n",
    "cluster_locations.foreachRDD(lambda rdd: update_cluster_subreddit_names(rdd))\n",
    "# cluster_locations = cluster_locations.mapValues(lambda x: Counter(x).most_common(1)[0][0])\n",
    "# cluster_locations.pprint()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = result.map(lambda cluster: (cluster, 1))\n",
    "# window of size 30s, and slides by 10s (very arbitrary)\n",
    "cluseter_counts = pairs.reduceByKeyAndWindow(\n",
    "    lambda x, y: x + y, lambda x, y: x - y, 30, 10)\n",
    "cluseter_counts.pprint()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create viz.json if doesn't exist and set every cluster size to 0\n",
    "with open(\"viz.json\", \"w\") as f:\n",
    "    total_data = {}\n",
    "    for i in range(k):\n",
    "        total_data[str(i)] = 0\n",
    "    json.dump(total_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_cluster_sizes(rdd):\n",
    "    if not rdd.isEmpty():\n",
    "        for x in rdd.collect():\n",
    "            with open(\"viz.json\", \"r\") as f:\n",
    "                total_data = json.load(f)\n",
    "            total_data[str(x[0])] += x[1]\n",
    "            with open(\"viz.json\", \"w\") as f:\n",
    "                json.dump(total_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the cluster sizes in sliding windows\n",
    "cluseter_counts.foreachRDD(lambda rdd: update_cluster_sizes(rdd))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2023-05-02 20:02:20\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2023-05-02 20:02:30\n",
      "-------------------------------------------\n",
      "(0, 98)\n",
      "(1, 2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2023-05-02 20:02:40\n",
      "-------------------------------------------\n",
      "(0, 161)\n",
      "(1, 37)\n",
      "(2, 2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2023-05-02 20:02:50\n",
      "-------------------------------------------\n",
      "(0, 214)\n",
      "(1, 83)\n",
      "(2, 3)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2023-05-02 20:03:00\n",
      "-------------------------------------------\n",
      "(0, 144)\n",
      "(1, 118)\n",
      "(2, 13)\n",
      "(3, 15)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2023-05-02 20:03:10\n",
      "-------------------------------------------\n",
      "(0, 118)\n",
      "(1, 114)\n",
      "(2, 21)\n",
      "(3, 24)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2023-05-02 20:03:20\n",
      "-------------------------------------------\n",
      "(0, 65)\n",
      "(1, 68)\n",
      "(2, 20)\n",
      "(3, 24)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2023-05-02 20:03:30\n",
      "-------------------------------------------\n",
      "(0, 70)\n",
      "(1, 52)\n",
      "(2, 22)\n",
      "(3, 23)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2023-05-02 20:03:40\n",
      "-------------------------------------------\n",
      "(0, 68)\n",
      "(1, 53)\n",
      "(2, 25)\n",
      "(3, 31)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2023-05-02 20:03:50\n",
      "-------------------------------------------\n",
      "(0, 91)\n",
      "(1, 69)\n",
      "(2, 39)\n",
      "(3, 41)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2023-05-02 20:04:00\n",
      "-------------------------------------------\n",
      "(0, 88)\n",
      "(1, 79)\n",
      "(2, 50)\n",
      "(3, 35)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2023-05-02 20:04:10\n",
      "-------------------------------------------\n",
      "(0, 88)\n",
      "(1, 81)\n",
      "(2, 45)\n",
      "(3, 32)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2023-05-02 20:04:20\n",
      "-------------------------------------------\n",
      "(0, 92)\n",
      "(1, 95)\n",
      "(2, 54)\n",
      "(3, 42)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2023-05-02 20:04:30\n",
      "-------------------------------------------\n",
      "(0, 62)\n",
      "(1, 64)\n",
      "(2, 31)\n",
      "(3, 34)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2023-05-02 20:04:40\n",
      "-------------------------------------------\n",
      "(0, 63)\n",
      "(1, 62)\n",
      "(2, 40)\n",
      "(3, 35)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2023-05-02 20:04:50\n",
      "-------------------------------------------\n",
      "(0, 72)\n",
      "(1, 59)\n",
      "(2, 39)\n",
      "(3, 30)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2023-05-02 20:05:00\n",
      "-------------------------------------------\n",
      "(0, 107)\n",
      "(1, 88)\n",
      "(2, 63)\n",
      "(3, 42)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2023-05-02 20:05:10\n",
      "-------------------------------------------\n",
      "(0, 95)\n",
      "(1, 81)\n",
      "(2, 77)\n",
      "(3, 40)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/02 20:05:30 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Socket data stream had no more data\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2023-05-02 20:05:20\n",
      "-------------------------------------------\n",
      "(0, 99)\n",
      "(1, 77)\n",
      "(2, 75)\n",
      "(3, 36)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/02 20:05:32 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:9999 - java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/maxime/Scientific_Programming/testvenv/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/maxime/Scientific_Programming/testvenv/lib/python3.8/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/usr/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n",
      "23/05/02 20:05:34 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:9999 - java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m ssc\u001b[39m.\u001b[39mstart()\n\u001b[0;32m----> 2\u001b[0m ssc\u001b[39m.\u001b[39;49mawaitTermination()\n",
      "File \u001b[0;32m~/Scientific_Programming/testvenv/lib/python3.8/site-packages/pyspark/streaming/context.py:239\u001b[0m, in \u001b[0;36mStreamingContext.awaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39mWait for the execution to stop.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39m    time to wait in seconds\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 239\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jssc\u001b[39m.\u001b[39;49mawaitTermination()\n\u001b[1;32m    240\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jssc\u001b[39m.\u001b[39mawaitTerminationOrTimeout(\u001b[39mint\u001b[39m(timeout \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m))\n",
      "File \u001b[0;32m~/Scientific_Programming/testvenv/lib/python3.8/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_args(\u001b[39m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/Scientific_Programming/testvenv/lib/python3.8/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1039\u001b[0m     \u001b[39mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[39mreturn\u001b[39;00m response, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m~/Scientific_Programming/testvenv/lib/python3.8/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[39m=\u001b[39m smart_decode(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mreadline()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mAnswer received: \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[39m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[39m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    670\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/02 20:05:36 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:9999 - java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat java.net.Socket.connect(Socket.java:556)\n",
      "\tat java.net.Socket.<init>(Socket.java:452)\n",
      "\tat java.net.Socket.<init>(Socket.java:229)\n",
      "\tat org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)\n",
      "\tat org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc.start()\n",
    "ssc.awaitTermination()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssc.stop(stopSparkContext=True, stopGraceFully=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
